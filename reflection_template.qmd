---
title: "STAT 331 Portfolio"
author: "Aaron Krimer"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an \_A-.

I belive I have met all or atleast almost all the objectives from a analytic standpoint. I have been a great team member and have continued to show growth and continued learning. I have worked really hard in this class and i think my work shows my effort and growth. 

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

    Location: Lab 7, Getting Set-up

```{r}
#| label: load-data
BlackfootFish <- read_csv(here("data", "BlackfootFish.csv"))

```

-   `xlsx`Location: check in 2.3

```{r}
agesxl <- read_xlsx(
  path = here::here("check-ins", "2.1-loading-data", "Ages_Data", "ages.xlsx"))

```

\

-   `txt`Location: check 2.3

```{r}
ages_mystery <- readr::read_delim(
  file = here::here("Week 2", "Check-ins", "Ages_Data", "ages_mystery.txt"),
  delim = "|")
```

**WD-2: I can select necessary columns from a dataset.\
**Location: Lab 1, Problem 5

```{r}
#| label: wd-2
# Select specific columns from the dataset
surveys_selected <- surveys %>% 
  select(species_id, weight, hindfoot_length)

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

    Lab 1, Problem 3

```{r}
#| label: wd-3-numeric
filtered_data <- surveys %>%
  filter(weight > 100)
```

-   character -- specifically a string (example must use functions from **stringr**)

    Location: Lab 5, Investigating the Gym and License Plate

```{r}
#| label: wd-3-string
drivers_license <- drivers_license %>%
  filter(str_detect(plate_number, "H42W"))

```

-   factor\
    Location: Lab 5, Problem 3

```{r}
#| label: wd-3-factor
species_filtered <- surveys %>%
  filter(species_id %in% c("DM", "DO"))
```

-   date (example must use functions from **lubridate**)\
    Location: Lab 3, Problem 5 (re-written using lubridate package)

```{r}
#| label: wd-3-date
library(lubridate)

surveys <- surveys %>%
  filter(year > 2000, month %in% c(1, 2, 3)) %>%
  mutate(date = ymd(paste(year, month, day, sep = "-")))

```

\

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

    Location: Lab 4 , Question 4

```{r}
#| label: wd-4-numeric
#| label: median-income-by-region-over-time

median_income_table <- ca_childcare %>%
  filter(study_year %in% c(2008, 2018)) %>%  # Filter for the years 2008 and 2018
  group_by(region, study_year) %>%  # Group by region and year
  summarize(median_income = median(mhi_2018, na.rm = TRUE)) %>%  # median household income
  
  pivot_wider(names_from = study_year, values_from = median_income) %>%  # Convert to wide format with years as columns
  arrange(desc(`2018`)) 

# View the result
median_income_table

```

-   character -- specifically a string (example must use functions from **stringr**)\
    Location: lab 4, question 3

```{r}
# Recoding counties into their respective Census regions
ca_childcare <- ca_childcare |> 
  mutate(county_name = str_remove(county_name, " County")) |>  # Remove "County" from names
  mutate(region = fct_recode(county_name,
                             # Northern California
                             "Northern California" = "Del Norte",
                             "Northern California" = "Siskiyou",
                             "Northern California" = "Modoc",
                             "Northern California" = "Humboldt",
                             "Northern California" = "Trinity",
                             "Northern California" = "Shasta",

))
```

-   factor (example must use functions from **forcats**)

    -   lab 4, question 3

```{r}
# Recoding counties into their respective Census regions
ca_childcare <- ca_childcare |> 
  mutate(county_name = str_remove(county_name, " County")) |>  # Remove "County" from names
  mutate(region = fct_recode(county_name,
                             # Northern California
                             "Northern California" = "Del Norte",
                             "Northern California" = "Siskiyou",
                             "Northern California" = "Modoc",
                             "Northern California" = "Humboldt",
                             "Northern California" = "Trinity",
                             "Northern California" = "Shasta",

))

```

-   date (example must use functions from **lubridate**)

    Location:Lab 4, question 6 (modified date entry to get first day of year using lubridate)

```{r}
library(lubridate)

# add a new date variable using lubridate
ca_childcare_long <- ca_childcare %>%
  mutate(date = make_date(study_year, 1, 1)) %>%  # made a date column for January 1 of each study_year
  pivot_longer(
    cols = c(mfcc_infant, mfcc_toddler, mfcc_preschool),  # select columns for different age groups
    names_to = "age_group",  # New column for age groups
    values_to = "median_price"  # Values will go in a column called "median_price"
  ) %>%
  mutate(age_group = recode(age_group, 
                            mfcc_infant = "Infant", 
                            mfcc_toddler = "Toddler", 
                            mfcc_preschool = "Preschooler"))  # rename age groups for readability

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`Location: Lab 5, modificaiton to a filter statement uses left_join() to combine the subset of addresses (northwestern_addresses) with the person table, rather than filtering within the table directly.

```{r}
northwestern_addresses <- data.frame(address_street_name = "Northwestern Dr")

first_witness <- northwestern_addresses %>%
  left_join(person, by = "address_street_name") %>%
  arrange(desc(address_number)) %>%
  slice(1)
```

-   `right_join()`Location: Lab 5 modification to witness locating : A right_join() prioritizes keeping all rows from the interview table where there is a match with the IDs in witness_ids. This works well here because the witness_ids dataframe acts as the "filter" for the interview table

```{r}
# Create a data frame for the relevant witness IDs
witness_ids <- data.frame(person_id = c(14887, 16371))

# Use right_join to retain only rows from witness_ids and their matches in interview
witness_interviews <- witness_ids %>%
  right_join(interview, by = "person_id")
```

-   `inner_join()`Lab 4, Question 2

```{r}
# Join the California counties with the childcare_costs dataset using county_fips_code
ca_childcare <- childcare_costs %>%
  inner_join(ca_counties, by = "county_fips_code")  # Join on the FIPS code

```

-   `full_join()`Lab 5, modifying searching for gold member

```{r}
# Create a filtered list of IDs matching the "48Z" pattern
gold_memberships <- data.frame(id = get_fit_now_member$id[str_starts(get_fit_now_member$id, "48Z")])

# Use full_join to include all gold_memberships and all data from get_fit_now_member
suspect_members <- gold_memberships %>%
  full_join(get_fit_now_member, by = "id") %>%
  filter(membership_status == "gold")

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`Location: Lab 5

```{r}
#| label: wd-6-semi
# Filter for gold members with membership_id starting with "48Z"
suspect_members <- get_fit_now_member %>%
  filter(membership_status == "gold", str_starts(id, "48Z"))

# Use semi_join() to filter drivers_license records for suspects found in suspect_members
filtered_licenses <- drivers_license %>%
  semi_join(suspect_members, by = c("id" = "person_id"))

print(filtered_licenses)


```

-   `anti_join()`Location: Lab 5 modified possible use of anti_join

```{r}
#| label: wd-6-anti
# Use anti_join() to filter drivers_license records that do NOT match suspect_members
non_matching_licenses <- drivers_license %>%
  anti_join(suspect_members, by = c("id" = "person_id"))

print(non_matching_licenses)


```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`Location: Lab 4, Problem 6

```{r}
# Reshape the dataset to create a long format
ca_childcare_long <- ca_childcare %>%
  pivot_longer(
    cols = c(mfcc_infant, mfcc_toddler, mfcc_preschool),  # Select columns for different age groups
    names_to = "age_group",  # New column for age groups
    values_to = "median_price"  # Values will go in a column called "median_price"
  ) %>%
  mutate(age_group = recode(age_group, 
                            mfcc_infant = "Infant", 
                            mfcc_toddler = "Toddler", 
                            mfcc_preschool = "Preschooler"))  # Rename age groups for readability


```

-   `pivot_wider()`Location: Lab 4, Problem 4

```{r}
#| label: median-income-by-region-over-time

median_income_table <- ca_childcare %>%
  filter(study_year %in% c(2008, 2018)) %>%  # Filter for the years 2008 and 2018
  group_by(region, study_year) %>%  # Group by region and year
  summarize(median_income = median(mhi_2018, na.rm = TRUE)) %>%  # median household income
  
  pivot_wider(names_from = study_year, values_from = median_income) %>%  # Convert to wide format with years as columns
  arrange(desc(`2018`)) 

# View the result
median_income_table
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:\
Lab 1\
Lab 2\
Lab 3\
Lab 4\
lab 5

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting\
    Location: Lab 7, question 2

```{r}
#| label: r-2-1
#| label: visual-of-missing-values-over-time
BlackfootFish %>%
  mutate(missing_weight = if_else(is.na(weight), "Missing", "Present")) %>%
  ggplot(aes(x = year, fill = missing_weight)) +
  geom_bar(position = "stack") +
  facet_grid(section ~ trip) +
  labs(
    title = "Frequency of Missing Weight Data Across Years, Sections, and Trips",
    x = "Year",
    y = "Count",
    fill = "Weight Status"
  ) +
  theme_minimal()

```

-   Example of **dplyr** pipeline\
    Location: Lab 2, Problem 9

```{r}
#| label: r-2-2
surveys %>%
  filter(!is.na(weight)) %>%
  group_by(species_id) %>%
  summarize(mean_weight = mean(weight, na.rm = TRUE))

```

-   Example of function formatting\
    Locoation: Lab 5, Problem 4

```{r}
#| label: r-2-3
calculate_mean <- function(data, column) {
  mean(data[[column]], na.rm = TRUE)
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context\
    Location: Challenge 7, Qestion 3\
    \
    3. Write a function to calculate the condition index of a fish, given inputs of weight and length.

    Consider whether you will write a function that works with vectors (accepting vectors as inputs) or a function that works with data frames (accepting a dataset and variable names as inputs)!

```{r}
#| label: condition-function
condition_index <- function(weight, length) {
  if (!is.numeric(weight) || !is.numeric(length)) {
    stop("weight and length must be numeric vectors.")
  }
  if (length(weight) != length(length)) {
    stop("Weight and length vectors must be same length.")
  }
  
  # calc condition index
  (weight / (length^3)) * 100
}
```

-   Example of function stops\
    Location: Lab 7, Problem 4

```{r}

rescale_02 <- function(x) {
  # inpyt validation
  if (!is.numeric(x)) {
    stop("Input vector must be numeric.")
  }
  if (length(x) <= 1) {
    stop("Input vector must have more than one element.")
  }
  
  # calc range for efficiency
  r <- range(x, na.rm = TRUE)
  (x - r[1]) / (r[2] - r[1])
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables\
    Location: Lab 4, Question 7

```{r}
#| label: scatterplot-median-income-vs-childcare-cost
ca_infant_childcare <- ca_childcare %>%
  filter(!is.na(mfcc_infant) & !is.na(mhi_2018))  # no missing values 

ggplot(ca_infant_childcare, aes(x = mhi_2018, y = mfcc_infant)) +
  geom_point(alpha = 0.6, color = "blue") +  # Scatterplot with points in blue
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear regression line in red
  labs(
    title = "Relationship Between Median Household Income and Infant Childcare Cost in California",
    x = "Median Household Income (2018 dollars) in California",
    y = "Median Weekly Price for Infant Care (USD)"
  ) +
  theme_minimal() +  # Clean theme
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Center and bold title
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels if needed
  )
```

-   at least one numeric variable and one categorical variable\
    Location: Lab 4, Question 6

```{r}
# Reshape the dataset to create a long format
ca_childcare_long <- ca_childcare %>%
  pivot_longer(
    cols = c(mfcc_infant, mfcc_toddler, mfcc_preschool),  # Select columns for different age groups
    names_to = "age_group",  # New column for age groups
    values_to = "median_price"  # Values will go in a column called "median_price"
  ) %>%
  mutate(age_group = recode(age_group, 
                            mfcc_infant = "Infant", 
                            mfcc_toddler = "Toddler", 
                            mfcc_preschool = "Preschooler"))  # Rename age groups for readability

# Create the plot
ggplot(ca_childcare_long, aes(x = study_year, y = median_price, color = region)) +
  geom_point(alpha = 0.5) +  
  geom_smooth(method = "loess", se = FALSE) +  # Loess smoother without confidence intervals
  facet_wrap(~ age_group, scales = "free_y", ncol = 3) +  # Facet by age group with 3 columns
  labs(
    title = "Weekly Median Price for Center-Based Childcare ($)",
    subtitle = "",
    x = "Study Year",
    y = "Median Price (USD)",
    color = "California Region"  # Label for the color legend
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +  # Adjust x-axis breaks
  scale_y_continuous(limits = c(100, 500)) +  # Match y-axis limits
  theme_minimal() +  # Use a clean theme
  theme(
    legend.position = "right",  # Place the legend to the right
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    panel.grid.minor = element_blank(),  # Hide minor grid lines for clarity
    strip.text = element_text(face = "bold", size = 12),  # Bold facet labels
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold")  # Center and bold title
  )
```

-   at least two categorical variables\
    Location: Lab 7, Question 2

```{r}
#| label: visual-of-missing-values-over-time
BlackfootFish %>%
  mutate(missing_weight = if_else(is.na(weight), "Missing", "Present")) %>%
  ggplot(aes(x = year, fill = missing_weight)) +
  geom_bar(position = "stack") +
  facet_grid(section ~ trip) +
  labs(
    title = "Frequency of Missing Weight Data Across Years, Sections, and Trips",
    x = "Year",
    y = "Count",
    fill = "Weight Status"
  ) +
  theme_minimal()
```

-   dates (timeseries plot)\
    Location: Lab 4, Question 6

```{r}
# Reshape the dataset to create a long format
ca_childcare_long <- ca_childcare %>%
  pivot_longer(
    cols = c(mfcc_infant, mfcc_toddler, mfcc_preschool),  # Select columns for different age groups
    names_to = "age_group",  # New column for age groups
    values_to = "median_price"  # Values will go in a column called "median_price"
  ) %>%
  mutate(age_group = recode(age_group, 
                            mfcc_infant = "Infant", 
                            mfcc_toddler = "Toddler", 
                            mfcc_preschool = "Preschooler"))  # Rename age groups for readability

# Create the plot
ggplot(ca_childcare_long, aes(x = study_year, y = median_price, color = region)) +
  geom_point(alpha = 0.5) +  
  geom_smooth(method = "loess", se = FALSE) +  # Loess smoother without confidence intervals
  facet_wrap(~ age_group, scales = "free_y", ncol = 3) +  # Facet by age group with 3 columns
  labs(
    title = "Weekly Median Price for Center-Based Childcare ($)",
    subtitle = "",
    x = "Study Year",
    y = "Median Price (USD)",
    color = "California Region"  # Label for the color legend
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +  # Adjust x-axis breaks
  scale_y_continuous(limits = c(100, 500)) +  # Match y-axis limits
  theme_minimal() +  # Use a clean theme
  theme(
    legend.position = "right",  # Place the legend to the right
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    panel.grid.minor = element_blank(),  # Hide minor grid lines for clarity
    strip.text = element_text(face = "bold", size = 12),  # Bold facet labels
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold")  # Center and bold title
  )

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head\
    Loaction: Lab 4, Question 7 - modified by tilting y axis

```{r}
#| label: scatterplot-median-income-vs-childcare-cost
ca_infant_childcare <- ca_childcare %>%
  filter(!is.na(mfcc_infant) & !is.na(mhi_2018))  # Filter out missing values

ggplot(ca_infant_childcare, aes(x = mhi_2018, y = mfcc_infant)) +
  geom_point(alpha = 0.6, color = "blue") +  # Scatterplot of two numeric variables
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear regression line
  labs(
    title = "Relationship Between Median Household Income and Infant Childcare Cost in California",
    x = "Median Household Income (2018 dollars) in California",
    y = "Median Weekly Price for Infant Care (USD)"
  ) +
  theme_minimal() +  # Clean theme
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Center and bold title
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    axis.title.y = element_text(angle = 0, vjust = 0.5)  # Tilt y-axis label for easier reading
  )
```

-   I can modify the text in my plot to be more readable\
    Location: lab 9, question 8

```{r}
all_simulations <- all_simulations |> 
  mutate(simulation_size = paste("Sample Size:", n))

# Create the plot
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.8) +
  geom_vline(aes(xintercept = df), color = "darkred", linetype = "dashed", size = 1) +
  facet_wrap(~simulation_size, scales = "free_y") +
  labs(
    title = "Distribution of Simulated Means Across Sample Sizes",
    subtitle = "Each Sample Size Shows Convergence to the True Mean (df = 10)",
    x = "Simulated Mean",
    y = "Frequency",
    caption = "Dashed line indicates the true mean of the Chi-Squared distribution"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 10),
    strip.text = element_text(face = "bold", size = 12)
  )
```

-   I can reorder my legend to align with the colors in my plot\
    Location: Lab 4, Problem 6 modified to achieve this using fct_reorder()

```{r}
#| label: recreate-plot
library(ggplot2)
library(tidyr)

# Reshape the dataset to create a long format
ca_childcare_long <- ca_childcare %>%
  pivot_longer(
    cols = c(mfcc_infant, mfcc_toddler, mfcc_preschool),  # Select columns for different age groups
    names_to = "age_group",  # New column for age groups
    values_to = "median_price"  # Values will go in a column called "median_price"
  ) %>%
  mutate(
    age_group = recode(age_group, 
                       mfcc_infant = "Infant", 
                       mfcc_toddler = "Toddler", 
                       mfcc_preschool = "Preschooler"),
    region = fct_reorder(region, median_price)  # Reorder regions based on median_price
  )

# Create the plot
ggplot(ca_childcare_long, aes(x = study_year, y = median_price, color = region)) +
  geom_point(alpha = 0.5) +  
  geom_smooth(method = "loess", se = FALSE) +  # Loess smoother without confidence intervals
  facet_wrap(~ age_group, scales = "free_y", ncol = 3) +  # Facet by age group with 3 columns
  labs(
    title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = "Median Price (USD)",
    color = "California Region"  # Label for the color legend
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +  # Adjust x-axis breaks
  scale_y_continuous(limits = c(100, 500)) +  # Match y-axis limits
  theme_minimal() +  # Use a clean theme
  theme(
    legend.position = "right",  # Place the legend to the right
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    strip.text = element_text(face = "bold", size = 12),  # Bold facet labels
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold")  # Center and bold title
  )

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors\
    Location lab 9, question 8

```{r}
all_simulations <- all_simulations |> 
  mutate(simulation_size = paste("Sample Size:", n))

# Create the plot
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, fill = "lawngreen", color = "peachpuff4", alpha = 0.8) +
  geom_vline(aes(xintercept = df), color = "papayawhip", linetype = "dashed", size = 1) +
  facet_wrap(~simulation_size, scales = "free_y") +
  labs(
    title = "Distribution of Simulated Means Across Sample Sizes",
    subtitle = "Each Sample Size Shows Convergence to the True Mean (df = 10)",
    x = "Simulated Mean",
    y = "Frequency",
    caption = "Dashed line indicates the true mean of the Chi-Squared distribution"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 10),
    strip.text = element_text(face = "bold", size = 12)
  )
```

\

-   I can use annotations\
    Location Lab 9, Question 8 - modified histogram plot to include annotations using geom_text(). The annotation highlights the true mean on each facet, enhancing the plot's clarity.

```{r}
#| label: plot-of-simulated-means-annotated
# Add a descriptive label for facets
all_simulations <- all_simulations |> 
  mutate(simulation_size = paste("Sample Size:", n))

# Calculate the mean for each sample size to annotate
annotations <- all_simulations %>%
  group_by(simulation_size) %>%
  summarize(mean_sim = mean(simulated_means), .groups = "drop") %>%
  mutate(label = paste0("Mean: ", round(mean_sim, 2)))

# Create the plot with annotations
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.8) +
  geom_vline(aes(xintercept = df), color = "darkred", linetype = "dashed", size = 1) +
  geom_text(
    data = annotations, 
    aes(x = mean_sim, y = 50, label = label),  # Place the annotation dynamically
    inherit.aes = FALSE,  # Prevent aesthetics from overriding
    vjust = -1, 
    color = "darkred", 
    size = 4
  ) +
  facet_wrap(~simulation_size, scales = "free_y") +
  labs(
    title = "Distribution of Simulated Means Across Sample Sizes",
    subtitle = "Each Sample Size Shows Convergence to the True Mean (df = 10)",
    x = "Simulated Mean",
    y = "Frequency",
    caption = "Dashed line indicates the true mean of the Chi-Squared distribution"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 10),
    strip.text = element_text(face = "bold", size = 12)
  )

```

-   I can be creative...\
    Location, Lab 9, Question 8 - modified. the modification is something i would add to any of my plots to make them easier to understand.

```{r}
#| label: plot-of-simulated-means-annotated
# Add a descriptive label for facets
all_simulations <- all_simulations |> 
  mutate(simulation_size = paste("Sample Size:", n))

# Calculate the mean for each sample size to annotate
annotations <- all_simulations %>%
  group_by(simulation_size) %>%
  summarize(mean_sim = mean(simulated_means), .groups = "drop") %>%
  mutate(label = paste0("Mean: ", round(mean_sim, 2)))

# Create the plot with annotations
ggplot(all_simulations, aes(x = simulated_means)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.8) +
  geom_vline(aes(xintercept = df), color = "darkred", linetype = "dashed", size = 1) +
  geom_text(
    data = annotations, 
    aes(x = mean_sim, y = 50, label = label),  # Place the annotation dynamically
    inherit.aes = FALSE,  # Prevent aesthetics from overriding
    vjust = -1, 
    color = "darkred", 
    size = 4
  ) +
  facet_wrap(~simulation_size, scales = "free_y") +
  labs(
    title = "Distribution of Simulated Means Across Sample Sizes",
    subtitle = "Each Sample Size Shows Convergence to the True Mean (df = 10)",
    x = "Simulated Mean",
    y = "Frequency",
    caption = "Dashed line indicates the true mean of the Chi-Squared distribution"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 10),
    strip.text = element_text(face = "bold", size = 12)
  )

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`Location: Lab 4, Question 4

```{r}
#| label: dvs-4-summarize 
#| label: median-income-by-region-over-time

median_income_table <- ca_childcare %>%
  filter(study_year %in% c(2008, 2018)) %>%  # Filter for the years 2008 and 2018
  group_by(region, study_year) %>%  # Group by region and year
  summarize(median_income = median(mhi_2018, na.rm = TRUE)) %>%  # median household income
  
  pivot_wider(names_from = study_year, values_from = median_income) %>%  # Convert to wide format with years as columns
  arrange(desc(`2018`)) 

# View the result
median_income_table
```

\

-   Example using `across()`

    Location Lab 7, Question 1

```{r}
#| label: dvs-4-across
#| label: find-missing-values
missing_values_summary <- BlackfootFish %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count") %>%
  filter(missing_count > 0)
```

**DVS-5: I can find summaries of variables across multiple groups.\
\
**

-   Example 1\
    Location: Lab 4, Question 4

```{r}
#| label: dvs-5-1
#| label: median-income-by-region-over-time

median_income_table <- ca_childcare %>%
  filter(study_year %in% c(2008, 2018)) %>%  # Filter for the years 2008 and 2018
  group_by(region, study_year) %>%  # Group by region and year
  summarize(median_income = median(mhi_2018, na.rm = TRUE)) %>%  # median household income
  
  pivot_wider(names_from = study_year, values_from = median_income) %>%  # Convert to wide format with years as columns
  arrange(desc(`2018`)) 

# View the result
median_income_table
```

-   Example 2\
    Location: Lab 7, Question 1 - modified to summarize multiple variables.

```{r}
#| label: dvs-5-2
#| label: visual-of-missing-values-over-time
BlackfootFish %>%
  mutate(missing_weight = if_else(is.na(weight), "Missing", "Present")) %>%
  group_by(year, section, trip, missing_weight) %>%  # Group by year, section, trip, and missing status
  summarize(count = n(), .groups = "drop") %>%  # Summarize the count of missing/present values
  ggplot(aes(x = year, y = count, fill = missing_weight)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_grid(section ~ trip) +
  labs(
    title = "Frequency of Missing Weight Data Across Years, Sections, and Trips",
    x = "Year",
    y = "Count",
    fill = "Weight Status"
  ) +
  theme_minimal()

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1\
    Location: lab 3, Question 7

```{r}
#| label: dvs-6-1
# code chunk for Q7
teacher_evals_clean %>%
  group_by(academic_degree, sex) %>%
  summarise(
    avg_seniority = mean(seniority, na.rm = TRUE),
    min_seniority = min(seniority, na.rm = TRUE),
    max_seniority = max(seniority, na.rm = TRUE),
    count_instructors = n()
  ) %>%
  print()

```

-   Example 2\
    Location: lab 9, Question 7 (challenge)

```{r}
#challenge

table_of_means <- all_simulations |> 
  group_by(n) |> 
  summarize(mean_of_means = mean(simulated_means), .groups = "drop") |> 
  arrange(n)  # Order table by n

#  nicely formatted table
table_of_means %>%
  kable(
    col.names = c("Sample Size (n)", "Mean of Simulated Means"),
    caption = "Summary of Simulated Means Across Different Sample Sizes"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

**DVS-7: I show creativity in my tables.**

-   Example 1

    Lab 9, Question 7

```{r}
#| label: dvs-7-1
table_of_means <- all_simulations |> 
  group_by(n) |> 
  summarize(mean_of_means = mean(simulated_means), .groups = "drop") |> 
  arrange(n)

# Nicely formatted table
table_of_means %>%
  kable(
    col.names = c("Sample Size (n)", "Mean of Simulated Means"),
    caption = "Summary of Simulated Means Across Different Sample Sizes"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

-   Example 2

    Lab 7, Question 1

```{r}
#| label: dvs-7-2
#| label: find-missing-values
missing_values_summary <- BlackfootFish %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count") %>%
  filter(missing_count > 0)

# Count rows with any missing values
observations_with_missing <- BlackfootFish %>%
  filter(if_any(everything(), is.na)) %>%
  summarise(total_observations_with_missing = n())

# Combine both pieces of information in a single output
missing_values_table <- bind_cols(missing_values_summary, observations_with_missing)
missing_values_table
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)\
    Location: Lab 7, Question 9

```{r}
#| label: pe-1-one-call
#| label: rescale-two-columns
BlackfootFish <- rescale_column(BlackfootFish, length, weight)

```

-   `across()`

    Location lab 7, question 1

```{r}
#| label: pe-1-across
missing_values_summary <- BlackfootFish %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count") %>%
  filter(missing_count > 0)

```

-   `map()` functions

    Location Lab 9, Question 1

```{r}
#| label: pe-1-map-1
#| label: function-simulation-for-random-babies

randomBabies <- function(nBabies){
  # sequence of babiesa and shuffle to simulate random allocation
  babies <- 1:nBabies
  shuffled <- sample(babies)
  
  # Count of correctly assigned
  sum(babies == shuffled)
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(4) 
                   )

# distribution of results
table(results) / 10000  # convert to proportions
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors
    -   Location Lab 7, Question 4

```{r}
#| label: pe-2-1
rescale_01 <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
```

-   Function that operates on data frames

    Location Lab 7, Question 8

```{r}
#| label: pe-2-2
rescale_column <- function(data, ...) {
  data %>%
    mutate(across(c(...), ~ rescale_01(.x)))
}
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

    Location lab 7, question 1

```{r}
#| label: pe-3-across
missing_values_summary <- BlackfootFish %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count") %>%
  filter(missing_count > 0)
```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

    Location Lab 9, Question 1

```{r}
#| label: pe-3-map-1
#| label: function-simulation-for-random-babies

randomBabies <- function(nBabies){
  # sequence of babiesa and shuffle to simulate random allocation
  babies <- 1:nBabies
  shuffled <- sample(babies)
  
  # Count of correctly assigned
  sum(babies == shuffled)
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(4) 
                   )

# distribution of results
table(results) / 10000  # convert to proportions
```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

    Location Lab 9, Question 6

```{r}
#| label: pe-3-map-2
all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, df = df), 
                                .f = simulate_means)
         ) |> 
  unnest(cols = simulated_means)

# see results
all_simulations
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

    Location Lab 4, Question 4

```{r}
#| label: pe-4-1
#| label: median-income-by-region-over-time

median_income_table <- ca_childcare %>%
  filter(study_year %in% c(2008, 2018)) %>%  # Filter for the years 2008 and 2018
  group_by(region, study_year) %>%  # Group by region and year
  summarize(median_income = median(mhi_2018, na.rm = TRUE)) %>%  # median household income
  
  pivot_wider(names_from = study_year, values_from = median_income) %>%  # Convert to wide format with years as columns
  arrange(desc(`2018`)) 

# View the result
median_income_table
```

-   I can connect a data wrangling pipeline into a `ggplot()`

    Locaiton : Lab 7, Question 2

```{r}
#| label: pe-4-2
#| label: visual-of-missing-values-over-time
BlackfootFish %>%
  mutate(missing_weight = if_else(is.na(weight), "Missing", "Present")) %>%
  ggplot(aes(x = year, fill = missing_weight)) +
  geom_bar(position = "stack") +
  facet_grid(section ~ trip) +
  labs(
    title = "Frequency of Missing Weight Data Across Years, Sections, and Trips",
    x = "Year",
    y = "Count",
    fill = "Weight Status"
  ) +
  theme_minimal()
```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1\
    Location Lab 9, Question 4

```{r}
#| label: dsm-1-1
simulate_means <- function(n, df) {
  map_dbl(.x = 1:n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}
```

-   Example 2\
    Location Lab 9, Question 1

```{r}
#| label: dsm-1-2

randomBabies <- function(nBabies){
  # sequence of babiesa and shuffle to simulate random allocation
  babies <- 1:nBabies
  shuffled <- sample(babies)
  
  # Count of correctly assigned
  sum(babies == shuffled)
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(4) 
                   )

# distribution of results
table(results) / 10000  # convert to proportions
```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1\
    Location Lab 4, Question 8

```{r}
#| label: dsm-2-1
reg_mod1 <- lm(mfcc_infant ~ mhi_2018, data = ca_infant_childcare)
summary(reg_mod1)
```

-   Example 2\
    Location: Lab 4, Question 7

```{r}
#| label: dsm-2-2
ca_infant_childcare <- ca_childcare %>%
  filter(!is.na(mfcc_infant) & !is.na(mhi_2018))  # no missing values 

ggplot(ca_infant_childcare, aes(x = mhi_2018, y = mfcc_infant)) +
  geom_point(alpha = 0.6, color = "blue") +  # Scatterplot with points in blue
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear regression line in red
  labs(
    title = "Relationship Between Median Household Income and Infant Childcare Cost in California",
    x = "Median Household Income (2018 dollars) in California",
    y = "Median Weekly Price for Infant Care (USD)"
  ) +
  theme_minimal() +  # Clean theme
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Center and bold title
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels if needed
  )
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

\
\
I am a huge fan of feedback especially really detailed feedback because it helps me improve my code by understanding exactly what it is I got wrong but more so understand how to improve my code. So every time I received feedback I would go back to my code and implement changes especially if they were significant like have species id vs species in my tables. or for example I received feedback on combining some filter calls into one which is an easy fix I implemented. I think over the course so far Ive made sure to eliminate problems/ issues with my code like always having code folding and a couple other lines in my yaml and try to make sure I dont get the same recurring mistakes or feedback in the following assignments.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

\
\
Lab two feed back and revisions, i think this is the best example of how I used revisions to change major and minor things details which I later didn't need to fix as i learned from editing my code.\
Initial feed back :

**Q1: Importing Data: You are expected to use the here() function from the here package to load in your data, not relative paths.\
Q3: Data Types of Variables: Could you write these as an itemized list so they are easier to read?\
Q6: Scatterplot Faceted by Species: Technically, I asked for species not species_id.\
Q7: Add Plot Title and Labels: Nice work figuring out how to center the plot title. However, best practices for plot titles is to have them left aligned.\
Q10: Side-by-Side Boxplots: Technically, I asked for species not species_id. This changes what you need to do in Q15.\
Q15: Add Labels & Possibly Tilt Names: What are these species of? If your title says species, do you need to have that included in your axis label?\
When you change to species, you will see why you need to rotate your axis labels...\
Q18: ANOVA Conclusion: Careful! You say two different conclusions.\
1. at least one group is different\
2. there is a significant difference in the means of the species.\
Which is the correct conclusion?\
\
**

Revision:

I now know how to use the here , although my file path does work , I can see why its nice to use the here() function so i re did the loading in my csv file. Will make sure to load in data in the future the way that is specified.

changed up my scatter plot. I ended up just re doing it. I think i got confused and went down the wrong path of making. BUt now im more confident in what I am creating in my file.

For question 10 I used species id instead of just species. I need to be more careful when reading what variables I am using in my code. So in future labs I will be paying more attention.

for question 15 I changed my axis labels. I can see the importants of being specific in my labels. It is an important part of making professional documents which is the goal of what I am doing. I will be making sure to be as specifc as possible in my future creation of labels.

question 18 I made a revised/ added a conclusion from my findings. I think I just didn't think my answer through . for future I need to make sure I read through the question and make sure I give a concrete conclusion from my findings.

\

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I think this course makes the thinking behind the code I use to achieve tasks develop with every project we do. I think my code shows that with each lab or activity ive been eliminating key issues and improve the efficiency and overall structure of my code. For example the murder mystery lab was really a free for all and a creative sandbox to use everything I have learned so far. And showing my step by step process in that lab along with other works has demonstrated what I have been learning and improving over the course so far.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

\
![](images/Screen%20Shot%202024-11-03%20at%209.07.29%20PM.png)

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

\
\
I think over the course so far Ive gotten a lot better at working together instead of divding tasks. I think its really easy to just say "you do this Ill do this " but working together has proven to be more productive because i actually better understand the flow of what we are doing. I have found that switching off is really efficient when learning knew functions and understanding the new libraries and functions we are using.\
\
